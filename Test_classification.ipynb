{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hidden-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "defensive-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = ['hand', 'Mug', 'Rline', 'Stapler', 'Tennis']\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model= torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, len(CATEGORIES))\n",
    "#model.fc= nn.Sequential(nn.Linear(512, 256), nn.ReLU(), nn.Dropout(0.2), nn.Linear(256, len(CATEGORIES)),nn.LogSoftmax(dim=1))\n",
    "\n",
    "model = model.cuda().eval().half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liquid-mileage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('classification_nonormalize_mix_5cat_100epochs_TennisRlineHandStaplerMug.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-exhaust",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meanstd import get_meanstd\n",
    "data_dir = 'road_following_testautomatic3'\n",
    "mean,std=get_meanstd(data_dir)\n",
    "#print(mean)\n",
    "#print(std)\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                #transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
    "                transforms.Resize((224, 224)),\n",
    "                #transforms.Grayscale(),\n",
    "                transforms.ToTensor(),\n",
    "                #transforms.Normalize(mean,std)\n",
    "                transforms.Normalize([0.5335, 0.4134, 0.4262], [0.1162, 0.0894, 0.0978])\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-engine",
   "metadata": {},
   "source": [
    "### Cell below just to know how much picture in each folder\n",
    "###### si '.ipynb_checkpoints' est present, rm -r jetracer/notebooks/classification_TRAIN/.ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlike-essence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number pictures in apex 890\n",
      "nb total image 890\n"
     ]
    }
   ],
   "source": [
    "somme=0\n",
    "for i in os.listdir(data_dir):\n",
    "    liste_cate = os.listdir(data_dir+'/'+i)\n",
    "    somme+=len(liste_cate)\n",
    "    print('number pictures in',str(i), len(liste_cate))\n",
    "          \n",
    "print('nb total image',somme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "loaded-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def predict_image(image):\n",
    "    np.set_printoptions(suppress=True)\n",
    "    image_tensor = test_transforms(image).half()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input = Variable(image_tensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    prediction_prob=torch.nn.functional.softmax(output,dim=1)\n",
    "    prediction_prob=prediction_prob.detach().cpu().numpy().flatten()\n",
    "    index = output.detach().cpu().numpy().flatten().argmax()\n",
    "    return index,prediction_prob\n",
    "\n",
    "def get_random_images(num):\n",
    "    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
    "    indices = list(range(len(data)))\n",
    "    np.random.shuffle(indices)\n",
    "    idx = indices[:num]\n",
    "    from torch.utils.data.sampler import SubsetRandomSampler\n",
    "    sampler = SubsetRandomSampler(idx)\n",
    "    loader = torch.utils.data.DataLoader(data, \n",
    "                   sampler=sampler, batch_size=num)\n",
    "    dataiter = iter(loader)\n",
    "    images, labels = dataiter.next()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-gibson",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil = transforms.ToPILImage()\n",
    "images, labels = get_random_images(5)\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "for ii in range(len(images)):\n",
    "    image = to_pil(images[ii])\n",
    "    #image=preprocess(image).half()\n",
    "    #image=color_isolation(image).half()\n",
    "    index,prediction_prob = predict_image(image)\n",
    "    sub = fig.add_subplot(1, len(images), ii+1)\n",
    "    res = int(labels[ii]) == index\n",
    "    sub.set_title(str(CATEGORIES[int(index)])+ \":\" + str(CATEGORIES[int(labels[ii])]))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    print(prediction_prob)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aboriginal-belle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-green",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-description",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-double",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
