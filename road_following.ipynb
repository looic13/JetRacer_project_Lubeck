{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create the model. This must match the model used in the interactive training notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "CATEGORIES = ['orange_line']\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(512, 2 * len(CATEGORIES))\n",
    "model = model.cuda().eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the saved model.  Enter the model path you used to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('road_following_colorIsolation.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert and optimize the model using ``torch2trt`` for faster inference with TensorRT.  Please see the [torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt) readme for more details.\n",
    "\n",
    "> This optimization process can take a couple minutes to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch2trt import torch2trt\n",
    "\n",
    "data = torch.zeros((1, 3, 224, 224)).cuda().half()\n",
    "\n",
    "model_trt = torch2trt(model, [data], fp16_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the optimized model using the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_trt.state_dict(), 'trt_road_following_colorIsolation.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the optimized model by executing the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('trt_road_following_colorIsolation.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the racecar class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetracer.nvidia_racecar import NvidiaRacecar\n",
    "\n",
    "car = NvidiaRacecar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the camera class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.csi_camera import CSICamera\n",
    "\n",
    "camera = CSICamera(width=224, height=224, capture_fps=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, execute the cell below to make the racecar move forward, steering the racecar based on the x value of the apex.\n",
    "\n",
    "Here are some tips,\n",
    "\n",
    "* If the car wobbles left and right,  lower the steering gain\n",
    "* If the car misses turns,  raise the steering gain\n",
    "* If the car tends right, make the steering bias more negative (in small increments like -0.05)\n",
    "* If the car tends left, make the steering bias more postive (in small increments +0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#WITH WHEELS MOVING\n",
    "from utils import preprocess\n",
    "import numpy as np\n",
    "\n",
    "STEERING_GAIN = 1.5 #0.95\n",
    "STEERING_BIAS = -0.30\n",
    "\n",
    "car.throttle = 0.2\n",
    "\n",
    "while True:\n",
    "    image = camera.read()\n",
    "    image = preprocess(image).half()\n",
    "    output = model_trt(image).detach().cpu().numpy().flatten()\n",
    "    x=output[0]\n",
    "    print(x)\n",
    "    \n",
    "    car.steering = x * STEERING_GAIN + STEERING_BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1CAT WITHOUT WHEELS MOVING \n",
    "from utils import preprocess\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "global dataset\n",
    "\n",
    "STEERING_GAIN = 0.95\n",
    "STEERING_BIAS = -0.30\n",
    "\n",
    "#car.throttle = 0.0\n",
    "\n",
    "while True:\n",
    "    image = camera.read()\n",
    "    image = preprocess(image).half()\n",
    "    output = model(image).detach().cpu().numpy().flatten()\n",
    "    outputtest=np.exp(output)/sum(np.exp(output))\n",
    "    prediction_ = model(image)\n",
    "    prediction_prob=torch.nn.functional.softmax(prediction_,dim=1)\n",
    "    print(\"pred\",prediction_.detach().cpu().numpy().flatten())\n",
    "    print(\"prob\",prediction_prob.detach().cpu().numpy().flatten())\n",
    "    print(\"\\n\")\n",
    "    print(outputtest)\n",
    "    category_number = outputtest.argmax()\n",
    "    print(category_number)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "    #x=output[0]\n",
    "    #car.steering = x * STEERING_GAIN + STEERING_BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2CAT WITHOUT WHEELS MOVING \n",
    "from utils import preprocess\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "global dataset\n",
    "\n",
    "STEERING_GAIN = 0.95\n",
    "STEERING_BIAS = -0.30\n",
    "\n",
    "#car.throttle = 0.0\n",
    "\n",
    "while True:\n",
    "    image = camera.read()\n",
    "    image = preprocess(image).half()\n",
    "    output = model_trt(image).detach().cpu().numpy().flatten()\n",
    "    prediction_ = model_trt(image)\n",
    "    prediction_prob=torch.nn.functional.softmax(prediction_,dim=1)\n",
    "    print(\"pred X_tennis\",prediction_.detach().cpu().numpy().flatten()[0])\n",
    "    #print(\"prob X_tennis\",prediction_prob.detach().cpu().numpy().flatten()[0])\n",
    "    print(\"pred X_staple\",prediction_.detach().cpu().numpy().flatten()[2])\n",
    "    #print(\"prob X_staple\",prediction_prob.detach().cpu().numpy().flatten()[2])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    #time.sleep(1)\n",
    "    #x=output[0]\n",
    "    #car.steering = x * STEERING_GAIN + STEERING_BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "from utils import preprocess\n",
    "import torch.nn.functional as F\n",
    "\n",
    "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
    "prediction_widget = ipywidgets.Image(format='jpeg', width=camera.width, height=camera.height)\n",
    "\n",
    "def live(state_widget, model, camera, prediction_widget):\n",
    "    global dataset\n",
    "    while state_widget.value == 'live':\n",
    "        image = camera.value\n",
    "        preprocessed = preprocess(image)\n",
    "        output = model(preprocessed).detach().cpu().numpy().flatten()\n",
    "        category_index = dataset.categories.index(category_widget.value)\n",
    "        x = output[2 * category_index]\n",
    "        y = output[2 * category_index + 1]\n",
    "        \n",
    "        x = int(camera.width * (x / 2.0 + 0.5))\n",
    "        y = int(camera.height * (y / 2.0 + 0.5))\n",
    "        \n",
    "        prediction = image.copy()\n",
    "        prediction = cv2.circle(prediction, (x, y), 8, (255, 0, 0), 3)\n",
    "        prediction_widget.value = bgr8_to_jpeg(prediction)\n",
    "            \n",
    "def start_live(change):\n",
    "    if change['new'] == 'live':\n",
    "        execute_thread = threading.Thread(target=live, args=(state_widget, model, camera, prediction_widget))\n",
    "        execute_thread.start()\n",
    "\n",
    "state_widget.observe(start_live, names='value')\n",
    "\n",
    "live_execution_widget = ipywidgets.VBox([\n",
    "    prediction_widget,\n",
    "    state_widget\n",
    "])\n",
    "\n",
    "display(live_execution_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
